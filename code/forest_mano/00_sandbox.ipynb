{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6318de5-6aa1-4247-9eb8-13e1e9093bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from helper_functions import tree\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from forest.jasmine.traj2stats import gps_stats_main, Hyperparameters\n",
    "from forest.constants import Frequency\n",
    "import sys\n",
    "import glob\n",
    "import yaml\n",
    "# TODO isolate get_subdirectories() to liz_helper_functions\n",
    "# from liz_helper_functions import get_subdirectories\n",
    "from tqdm import tqdm \n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "import requests\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.ops import transform\n",
    "\n",
    "from forest.bonsai.simulate_gps_data import bounding_box\n",
    "from forest.constants import Frequency, OSM_OVERPASS_URL, OSMTags\n",
    "from forest.jasmine.data2mobmat import (gps_to_mobmat, infer_mobmat,\n",
    "                                        great_circle_dist,\n",
    "                                        pairwise_great_circle_dist)\n",
    "from forest.jasmine.mobmat2traj import (imp_to_traj, impute_gps, locate_home,\n",
    "                                        num_sig_places)\n",
    "from forest.jasmine.sogp_gps import bv_select\n",
    "from forest.poplar.legacy.common_funcs import (datetime2stamp, read_data,\n",
    "                                               stamp2datetime,\n",
    "                                               write_all_summaries)\n",
    "from forest.utils import get_ids\n",
    "\n",
    "\n",
    "\n",
    "# Get the absolute path to the directory this script lives in\n",
    "SCRIPT_DIR = os.getcwd() # os.path.dirname(os.path.abspath(__file__)) for script\n",
    "\n",
    "# Construct the path to the config file relative to the script\n",
    "CONFIG_PATH = os.path.join(SCRIPT_DIR, \"../../config/old_HOPE_config.yaml\")\n",
    "# # quick and dirty hardcoding for testing\n",
    "# CONFIG_PATH = \"/n/onnela_dp_l3/Lab/HOPE/beiwe/config/HOPE_config.yaml\"\n",
    "CONFIG_DIR = os.path.dirname(CONFIG_PATH)\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# data_dir = os.path.abspath(os.path.join(CONFIG_DIR, config[\"data_dir\"]))\n",
    "raw_data_dir = os.path.abspath(os.path.join(CONFIG_DIR, config[\"raw_data_dir\"]))\n",
    "raw_data_folder = os.path.abspath(os.path.join(raw_data_dir, config[\"raw_data_folder\"]))\n",
    "metadata_path = os.path.abspath(os.path.join(CONFIG_DIR, config[\"metadata_path\"]))\n",
    "\n",
    "data_dir = os.path.abspath(os.path.join(CONFIG_DIR, config[\"data_dir\"]))\n",
    "\n",
    "\n",
    "\n",
    "dest_dir = raw_data_folder\n",
    "\n",
    "beiwe_id_df = pd.read_csv(metadata_path, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e115b83-80ff-4bc0-9dbe-535435587f3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_path_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m file_path = \u001b[43mfile_path_array\u001b[49m[i]  \u001b[38;5;66;03m# The file that caused the error\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n",
      "\u001b[31mNameError\u001b[39m: name 'file_path_array' is not defined"
     ]
    }
   ],
   "source": [
    "file_path = file_path_array[i]  # The file that caused the error\n",
    "with open(file_path, 'r') as f:\n",
    "    for _ in range(5):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1f241ab-9fc0-4305-974e-ce2a0f7eb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jasmine job 5450095 debugging\n",
    "\n",
    "FILE_PATH = \"/n/onnela_dp_l3/Lab/HOPE/beiwe/data/raw/manual_HOPE_paper2_download/ige4zl6o/gps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d279a075-dd3f-4c75-af77-0d04176e57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gps_quality_check(study_folder: str, study_id: str) -> float:\n",
    "    \"\"\"The function checks the gps data quality.\n",
    "\n",
    "    Args:\n",
    "        study_folder (str): The path to the study folder.\n",
    "        study_id (str): The id code of the study.\n",
    "    Returns:\n",
    "        a scalar between 0 and 1, bigger means better data quality\n",
    "            (percentage of data which meet the criterion)\n",
    "    \"\"\"\n",
    "    gps_path = f\"{study_folder}/{study_id}/gps\"\n",
    "    if not os.path.exists(gps_path):\n",
    "        quality_check = 0.\n",
    "    else:\n",
    "        file_list = os.listdir(gps_path)\n",
    "        for i, _ in enumerate(file_list):\n",
    "            if file_list[i][0] == \".\":\n",
    "                file_list[i] = file_list[i][2:]\n",
    "        file_path = [\n",
    "            f\"{gps_path }/{file_list[j]}\"\n",
    "            for j, _ in enumerate(file_list)\n",
    "        ]\n",
    "        file_path_array = np.sort(np.array(file_path))\n",
    "        # check if there are enough data for the following algorithm\n",
    "        quality_yes = 0.\n",
    "        for i, _ in enumerate(file_path_array):\n",
    "            df = pd.read_csv(file_path_array[i])\n",
    "            if df.shape[0] > 60:\n",
    "                quality_yes = quality_yes + 1.\n",
    "        quality_check = quality_yes / (len(file_path_array) + 0.0001)\n",
    "    return quality_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0fc1918-6122-4d59-b149-7ef1814da861",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUGGY_ID = \"ige4zl6o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4044422-4a96-4091-ab4f-fa5601b66280",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 6 fields in line 3, saw 7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test = \u001b[43mgps_quality_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_folder\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_data_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mBUGGY_ID\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mgps_quality_check\u001b[39m\u001b[34m(study_folder, study_id)\u001b[39m\n\u001b[32m     25\u001b[39m quality_yes = \u001b[32m0.\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(file_path_array):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m df.shape[\u001b[32m0\u001b[39m] > \u001b[32m60\u001b[39m:\n\u001b[32m     29\u001b[39m         quality_yes = quality_yes + \u001b[32m1.\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/n/onnela_dp_l3/Lab/envs/.forest_venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/n/onnela_dp_l3/Lab/envs/.forest_venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/n/onnela_dp_l3/Lab/envs/.forest_venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/n/onnela_dp_l3/Lab/envs/.forest_venv/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 6 fields in line 3, saw 7\n"
     ]
    }
   ],
   "source": [
    "test = gps_quality_check(study_folder = raw_data_folder, study_id = BUGGY_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8486947-ffa7-4524-8fac-5de2d1f6dcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dce44e09-b1d1-4f4f-acab-a15cfd5ec09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/n/onnela_dp_l3/Lab/HOPE/beiwe/data/raw/manual_HOPE_paper2_download'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forest_venv",
   "language": "python",
   "name": "forest_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
